{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Import the necessary dependent libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "from module import MLPModule\n",
    "from utils import aggregate_weights, save_global_measure, load_client_data, calculate_global_measures\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from client import EMClient\n",
    "from client_selector import ClientSelector\n",
    "import time"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set the necessary parameters and hyperparameters for the experiment and model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "seed = 54\n",
    "dataset_name = \"n-baiot\"\n",
    "selector_type = 'random'\n",
    "num_rounds = 25\n",
    "input_dim = 0\n",
    "n_mix_distribute = 2\n",
    "select_num = 50\n",
    "\n",
    "if dataset_name == \"unsw-nb15\":\n",
    "    input_dim = 47\n",
    "elif dataset_name == \"n-baiot\":\n",
    "    input_dim = 115\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "# elif torch.backends.mps.is_available():\n",
    "#     device = torch.device(\"mps:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "hyperparameters = {\n",
    "    'input_dim': input_dim,\n",
    "    'lr': 0.00001,\n",
    "    'models_num': n_mix_distribute,\n",
    "    'hidden_neurons_num': 512,\n",
    "    'batch_size': 128,\n",
    "    'seed': seed,\n",
    "    'device': device\n",
    "} \n",
    "\n",
    "select_hyperparameters = {\n",
    "    'enable': True,\n",
    "    'is_train': False,\n",
    "    'type_name': selector_type,\n",
    "    'lr': 0.001,\n",
    "    'global_models_num': n_mix_distribute,\n",
    "    'pca_n_components': 20,\n",
    "    'buffer_batch_size': 16,\n",
    "    'buffer_size': 1000,\n",
    "    'reward_lambda_value': 64,\n",
    "    'target_accuracy': 0.99,\n",
    "    'epsilon_start': 0.8,\n",
    "    'epsilon_end': 0.2,\n",
    "    'epsilon_decay': 100,\n",
    "    'gamma': 0.99,\n",
    "    'model_path': \"./dqn_models/05-12-2023_14-35-37_n-baiot\",\n",
    "    'seed': seed,\n",
    "    'device': device\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "Get all client data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client_data_list = load_client_data(os.path.join(dataset_name, \"split\"), device)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generate clients"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_clients(client_data, hyperparameter):\n",
    "    client_list = []\n",
    "    for i, (train_set, test_set, val_set) in enumerate(client_data):\n",
    "        c = EMClient(\n",
    "            id=i,\n",
    "            hyperparameters=hyperparameter,\n",
    "            train_set=train_set,\n",
    "            test_set=test_set,\n",
    "            val_set=val_set,\n",
    "        )\n",
    "        client_list.append(c)\n",
    "    return client_list\n",
    "clients = create_clients(client_data_list, hyperparameters)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generate client selector"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "selector = ClientSelector(clients, select_num, select_hyperparameters)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "FedEM training process"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialize multiple global models for each mixture distribution\n",
    "global_models = [MLPModule(hyperparameters) for _ in range(n_mix_distribute)]\n",
    "\n",
    "# Pre-trained\n",
    "model_weights_lists = [[] for _ in range(n_mix_distribute)]\n",
    "client_n_samples_list = {}\n",
    "\n",
    "for client in clients:\n",
    "    client.receive_global_model(global_models)\n",
    "    client_models_parameters, client_measures, client_n_samples = client.local_fit_and_upload_parameters()\n",
    "    client_n_samples_list[client.id] = client_n_samples\n",
    "\n",
    "    for i in range(n_mix_distribute):\n",
    "        model_weights_lists[i].append(client_models_parameters[i])\n",
    "\n",
    "for i in range(n_mix_distribute):\n",
    "    global_models[i].set_parameters(aggregate_weights(model_weights_lists[i], client_n_samples_list))\n",
    "    \n",
    "selector.fit_pca(global_models, model_weights_lists)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Record training results\n",
    "record_global_train_measures = [None] * num_rounds\n",
    "record_global_val_measures = [None] * num_rounds\n",
    "\n",
    "pbar = tqdm(total=num_rounds)\n",
    "\n",
    "train_time_record = [None] * num_rounds\n",
    "start_time = time.time()\n",
    "\n",
    "# Perform num_rounds rounds of training\n",
    "for idx in range(num_rounds):\n",
    "    # print(\"idx: \", idx)\n",
    "    client_n_samples_list = {}\n",
    "\n",
    "    all_client_train_measures = { 'accuracy': {}, 'fpr': {}, 'tpr': {}, 'ber': {}, 'loss': {} }\n",
    "    all_client_val_measures = { 'accuracy': {}, 'fpr': {}, 'tpr': {}, 'ber': {}, 'loss': {} }\n",
    "\n",
    "    selected_client = selector.sample_clients(global_models, model_weights_lists)\n",
    "    model_weights_lists = [[] for _ in range(n_mix_distribute)]\n",
    "\n",
    "    for client in selected_client:\n",
    "        # Client receives new global models\n",
    "        client.receive_global_model(global_models)\n",
    "\n",
    "        # The client trains the models locally\n",
    "        client_models_parameters, client_measures, client_n_samples = client.local_fit_and_upload_parameters()\n",
    "        client_n_samples_list[client.id] = client_n_samples\n",
    "\n",
    "        for i in range(n_mix_distribute):\n",
    "            model_weights_lists[i].append(client_models_parameters[i])\n",
    "\n",
    "        for key in all_client_train_measures:\n",
    "            all_client_train_measures[key][client.id] = (client_measures['train'][key])\n",
    "            all_client_val_measures[key][client.id] = (client_measures['val'][key])\n",
    "\n",
    "    global_train_measures, global_val_measures = calculate_global_measures(selected_client,\n",
    "                                                                           all_client_train_measures,\n",
    "                                                                           all_client_val_measures,\n",
    "                                                                           display_result=True)\n",
    "    \n",
    "    record_global_train_measures[idx] = global_train_measures\n",
    "    record_global_val_measures[idx] = global_val_measures\n",
    "\n",
    "    # Aggregate new global models\n",
    "    for i in range(n_mix_distribute):\n",
    "        global_models[i].set_parameters(aggregate_weights(model_weights_lists[i], client_n_samples_list))\n",
    "\n",
    "    selector.update_dqn(global_models, model_weights_lists, global_val_measures['accuracy'])\n",
    "\n",
    "    train_time_record[idx] = time.time() - start_time\n",
    "    pbar.update(1)\n",
    "pbar.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save experiment results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "name = \"\"\n",
    "if name == 100:\n",
    "    name = \"FEDQ\"\n",
    "if selector_type != \"random\":\n",
    "    name = \"FEDQ\"+str(select_num)\n",
    "elif name != 100:\n",
    "    name = \"FedEM_random_\"+str(select_num)\n",
    "    \n",
    "save_global_measure(record_global_train_measures, \"train_measures_\"+dataset_name+\".csv\", name)\n",
    "save_global_measure(record_global_val_measures, \"val_measures_\"+dataset_name+\".csv\", name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save DQN model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "selector.save_model(dataset_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test the performance of the model on the unseen test set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_client_measures = {\n",
    "    'accuracy': [],\n",
    "    'fpr': [],\n",
    "    'tpr': [],\n",
    "    'ber': [],\n",
    "    'loss': []\n",
    "}\n",
    "client_n_samples_list = {}\n",
    "\n",
    "# Iterate over clients and evaluate using each global model\n",
    "for client in clients:\n",
    "    client_n_samples = 0\n",
    "    client_measures_sum = {\n",
    "        'accuracy': 0,\n",
    "        'fpr': 0,\n",
    "        'tpr': 0,\n",
    "        'ber': 0,\n",
    "        'loss': 0\n",
    "    }\n",
    "\n",
    "    # Client receives new global models\n",
    "    client.receive_global_model(global_models)\n",
    "\n",
    "    # Evaluate using each global model and aggregate results\n",
    "    for global_model in global_models:\n",
    "        client_measures, current_n_samples = client.evaluate_test_set()\n",
    "        client_n_samples += current_n_samples\n",
    "        for key in client_measures:\n",
    "            client_measures_sum[key] += client_measures[key]\n",
    "\n",
    "    # Average the measures over all models\n",
    "    for key in client_measures_sum:\n",
    "        client_measures_sum[key] /= len(global_models)\n",
    "\n",
    "    client_n_samples_list[client.id] = client_n_samples\n",
    "\n",
    "    for key in all_client_measures:\n",
    "        all_client_measures[key].append(client_measures_sum[key])\n",
    "\n",
    "global_measures = {}\n",
    "for key in all_client_measures:\n",
    "    global_measures[key] = sum([all_client_measures[key][c.id] * client_n_samples_list[c.id] for c in clients]) / sum(client_n_samples_list.values())\n",
    "\n",
    "print(\"Global Test Set Loss:\", global_measures['loss'])\n",
    "print(\"Global Test Set Accuracy:\", global_measures['accuracy'])\n",
    "print(\"Global Test Set FPR:\", global_measures['fpr'])\n",
    "print(\"Global Test Set TPR:\", global_measures['tpr'])\n",
    "print(\"Global Test Set BER:\", global_measures['ber'])"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
